{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Recognition\n",
    "### Tim Nguyen & Neeraj Shah\n",
    "---\n",
    "\n",
    "\n",
    "In the following code portions below, we implement a barebones version of how audio recognition works using the core concept sof digital signal processing.  This involves sampling the analog signal (sound input), converting it a digital signal, performing a discrete fourier transform, and matching the audio fingerprints with a predefined database.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "1) Need to have PyAudio library.  Install with python's package manager `pip` :\n",
    "\n",
    "`pip install pyaudio`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyaudio",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1a3eb50c11d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pyaudio"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "import time\n",
    "import copy\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the songs in the library to create the TRUE database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below deals with audio input\n",
    "\n",
    "Records audio and saves to a .WAV file for a specified amount of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def record(fileName):\n",
    "    \n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100  # Sampling Rate\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = fileName\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording Audio ... \")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording Finished\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "def play(fileName):\n",
    "\n",
    "    wf = wave.open(fileName, 'rb')\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        data = wf.readframes(frame_count)\n",
    "        return (data, pyaudio.paContinue)\n",
    "\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True,\n",
    "                    stream_callback=callback)\n",
    "\n",
    "    stream.start_stream()\n",
    "\n",
    "    i = 0\n",
    "    # while stream.is_active():\n",
    "    while i < 125:\n",
    "        time.sleep(0.1)\n",
    "        i += 1\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    wf.close()\n",
    "\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "record(\"test.wav\")  # Test record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'play' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a14b6921c9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"billiejeanwav.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'play' is not defined"
     ]
    }
   ],
   "source": [
    "play(\"billiejeanwav.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'wavfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-448e57dbfa04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'billiejeanwav.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxextent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'wavfile'"
     ]
    }
   ],
   "source": [
    "sample_rate, X = scipy.io.wavfile.read('billiejeanwav.wav')\n",
    "print (sample_rate, X.shape )\n",
    "plt.specgram(X[:,0], Fs=sample_rate, xextent=(0,30))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.pcolormesh(times, frequencies, spectogram)\n",
    "#plt.imshow(spectogram)\n",
    "#plt.ylabel('Frequency [Hz]')\n",
    "#plt.xlabel('Time [sec]')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Database Here:\n",
    "\n",
    "The database will store several snippets of the songs we wish to be able to recognize.\n",
    "We will use a hashtable, where the key is several high frequencies and value is an array of time and song.\n",
    "We will choose high frequencies between several intervals. Each key will have four frequencies.\n",
    "\n",
    "Our frequency ranges will be from 0-40Hz, 40-80Hz, 80-120Hz, and 120Hz+\n",
    "In the future, we may modify this to include more songs.\n",
    "Each snippet from which we obtain frequencies will be one second long.\n",
    "Since this is such a small frame of time, we can ignore time from here on out.\n",
    "The only place time will be included is in the value of our hashtable. It can show us exactly where\n",
    "program associated our recorded sound with our stored song. This is useful for debugging\n",
    "\n",
    "Even with a four-point key, we still may not completely recognize a song--two sets of four frequencies may map to the same song. This is when it will useful to make multiple matches. We will track all associations and narrow the pool the longer we play the song. At the end, we should have correctly identified a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-10-50e55f4a5cd6>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-50e55f4a5cd6>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    for each song:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database = {}\n",
    "maxChunk = 5\n",
    "songSnippet = []\n",
    "for i in range(len(song)):\n",
    "    songSnippet.append(song[i])\n",
    "    if i > maxChunk:\n",
    "        #Know associated time passed\n",
    "        # Take fft here (songSnippet)\n",
    "        \n",
    "        \n",
    "#or \n",
    "\n",
    "for each song:\n",
    "    pxx, freqs, bins = plt.specgram(song)\n",
    "    for i in range(len(pxx)):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Actual Program\n",
    "Keep track of \"matches\" and narrow song options as the song plays for a longer time. In the best case scenario, it should only need to play for the size of one song snippet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-13e5079ddd7d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-13e5079ddd7d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    while(song not recognized)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "while(song not recognized)\n",
    "    #Increment through the song by snippet interval and each time, identify the four max frequencies\n",
    "    #In each category.\n",
    "    \n",
    "    \n",
    "    associatedSongs = []\n",
    "    #store all associated songs within this array\n",
    "    #add noise here--in other words, allow matches to be within plus-or-minus five percent of obtained frequency.\n",
    "    #This will increase the number of matches, but will make sure we don't reject the right song (Type 2 error)\n",
    "    #We don't add new matches after the first snippet of playback time. \n",
    "    \n",
    "    #Continue to find matches till there is only one element left in the array.\n",
    "    \n",
    "    if len(associatedSongs) == 1:\n",
    "        \n",
    "        print(associatedSongs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
